{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gracelcai/career-launch-group-13/blob/main/ExerciseModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup:"
      ],
      "metadata": {
        "id": "mRN5mUNIetKp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eI5Q8_DHmrp8"
      },
      "outputs": [],
      "source": [
        "# import PyTorch\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Import torchvision\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check versions\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "YncCJLGXbdL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing data:"
      ],
      "metadata": {
        "id": "EAe2PCvEev5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup training data\n",
        "train_data = # TODO\n",
        "\n",
        "test_data = # TODO"
      ],
      "metadata": {
        "id": "QGzFHp7IY9m9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn train dataset into DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# setup batch size hyperparameter\n",
        "BATCH_SIZE = 32\n",
        "train_dataloader = DataLoader(dataset = train_data,\n",
        "                           batch_size = BATCH_SIZE,\n",
        "                           shuffle = True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset = test_data,\n",
        "                             batch_size = BATCH_SIZE,\n",
        "                             shuffle = False)\n",
        "\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "Hl7JjbM9ZCi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the Model:"
      ],
      "metadata": {
        "id": "7Bx6Nof_e0ZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class Exercise_Model(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_shape: int,\n",
        "               hidden_units: int,\n",
        "               output_shape: int):\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(\n",
        "        # TODO\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return # TODO"
      ],
      "metadata": {
        "id": "iZnS92CIatCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup model\n",
        "\n",
        "model = Exercise_Model(\n",
        "    input_shape = ,\n",
        "    hidden_units = ,\n",
        "    output_shape =\n",
        ").to(device)\n",
        "\n",
        "model"
      ],
      "metadata": {
        "id": "eVJd0jx9bAsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### POSSIBLY WRONG\n",
        "from helper_functions import accuracy_fn\n",
        "loss_fn = nn.CrossEntropyLoss() # measures how wrong model is TODO: are we using CrossEntropyLoss?\n",
        "optimizer = torch.optim.SGD(params = model.parameters(), lr = 0.1) # TODO: Do we want to use SGD?"
      ],
      "metadata": {
        "id": "buEuYRzib2vY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Testing Functions"
      ],
      "metadata": {
        "id": "zw-J53b5e2-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device: torch.device = device):\n",
        "  \"\"\" Performs a training with model trying to learn on data_loader\"\"\"\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  # Add loop to loop through training batches\n",
        "  for batch, (X, y) in enumerate(data_loader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    y_pred = model(X)\n",
        "\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "\n",
        "    train_acc += accuracy_fn(y_true = y,\n",
        "                             y_pred = y_pred.argmax(dim = 1)) # from logits -> prediction labels\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    #TODO: change this up (below)\n",
        "    if batch % 400 == 0:\n",
        "      print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
        "\n",
        "  # Divide total train loss by length of train dataloader\n",
        "  train_loss /= len(data_loader)\n",
        "  train_acc /= len(data_loader)\n",
        "  print(f\"Train loss: {train_loss:.5f} | train acc: {train_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "QhguKZWXcHPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "              data_loader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn,\n",
        "              device: torch.device = device):\n",
        "  \"\"\"Performs testing loop step on model going over data_loader\"\"\"\n",
        "  test_loss, test_acc = 0, 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for X, y in data_loader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      test_pred = model(X)\n",
        "\n",
        "      test_loss += loss_fn(test_pred, y)\n",
        "      test_acc += accuracy_fn(y_true = y, y_pred = test_pred.argmax(dim = 1))\n",
        "\n",
        "\n",
        "    test_loss /= len(data_loader)\n",
        "    test_acc /= len(data_loader)\n",
        "    print(f\"Test loss: {test_loss:.5f} | Test acc: {test_acc:.2f}%\\n\")"
      ],
      "metadata": {
        "id": "EFVnqNUNc-9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If we want to time our model?\n",
        "from timeit import default_timer as timer\n",
        "def print_train_time(start: float, end: float, device: torch.device = None):\n",
        "  \"\"\"\n",
        "  Prints difference between start and end time\n",
        "  \"\"\"\n",
        "  total_time = end - start\n",
        "  print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "  return total_time"
      ],
      "metadata": {
        "id": "Ny__2Be9dTU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Testing the Model:"
      ],
      "metadata": {
        "id": "IOKmt4VAeqPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Set seed and start timer\n",
        "torch.manual_seed(42)\n",
        "train_start = timer()\n",
        "\n",
        "# set number of epochs (small for faster training time)\n",
        "epochs = 3\n",
        "\n",
        "# Create training and testing loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n-----\")\n",
        "\n",
        "  # Training\n",
        "  train_loss = 0\n",
        "\n",
        "  # Add loop to loop through training batches\n",
        "  for batch, (X, y) in enumerate(train_dataloader):\n",
        "    model.train()\n",
        "\n",
        "    y_pred = model(X)\n",
        "\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 400 == 0:\n",
        "      print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
        "\n",
        "  # Divide total train loss by length of train dataloader\n",
        "  train_loss /= len(train_dataloader)\n",
        "\n",
        "  # Testing\n",
        "  test_loss, test_acc = 0, 0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X_test, y_test in test_dataloader:\n",
        "\n",
        "      test_pred = model(X_test)\n",
        "\n",
        "      test_loss += loss_fn(test_pred, y_test)\n",
        "\n",
        "      test_acc += accuracy_fn(y_true = y_test, y_pred = test_pred.argmax(dim = 1))\n",
        "\n",
        "    test_loss /= len(test_dataloader)\n",
        "\n",
        "    test_acc /= len(test_dataloader)\n",
        "\n",
        "  # print whats happening\n",
        "  print(f\"\\nTrain loss: {train_loss:.4f} | Test loss: {test_loss:.4f}, Test acc: {test_acc:.4f}\")\n",
        "\n",
        "# Calculate training time\n",
        "train_end = timer()\n",
        "train_time = print_train_time(start = train_start,\n",
        "                              end = train_end,\n",
        "                              device = str(next(model.parameters()).device))"
      ],
      "metadata": {
        "id": "cLxV_WUedk4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating Model:"
      ],
      "metadata": {
        "id": "oL5hduT_fBA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn):\n",
        "  \"\"\" Returns dictionary containing results of model predicting on data_loader\"\"\"\n",
        "  loss, acc = 0, 0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X, y in tqdm(data_loader):\n",
        "\n",
        "      # Make predictions\n",
        "      y_pred = model(X)\n",
        "\n",
        "      # Accumulate loss and acc values per batch\n",
        "      loss += loss_fn(y_pred, y)\n",
        "\n",
        "      acc += accuracy_fn(y_true = y, y_pred = y_pred.argmax(dim = 1))\n",
        "    # scale loss and acc to find average loss/acc per batch\n",
        "    loss /= len(data_loader)\n",
        "    acc /= len(data_loader)\n",
        "\n",
        "  # TODO: idk if __class__.__name__ is gonna be a thing or not\n",
        "  return {\"model_name\": model.__class__.__name__,\n",
        "          \"model_loss\": loss.item(),\n",
        "          \"model_acc\": acc}\n",
        "# Calculate model 0 results on dataset\n",
        "model_results = eval_model(model = model,\n",
        "                           data_loader = test_dataloader,\n",
        "                           loss_fn = loss_fn,\n",
        "                           accuracy_fn = accuracy_fn,\n",
        "                           device = device)\n",
        "model_results"
      ],
      "metadata": {
        "id": "4aJrdmcBfCYJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}